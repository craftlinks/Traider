import asyncio
# ---------------------------------------------------------------------------
# Standard library imports
# ---------------------------------------------------------------------------
from concurrent.futures import ProcessPoolExecutor
from datetime import datetime
import os
import pprint
import random
import time
import uuid

# Models
from traider.yfinance._models import PressRelease
from traider.yfinance import EarningsEvent
from traider.messagebus.channels import Channel
from traider.messagebus.protocol import MessageBroker
from traider.messagebus.brokers.memory import InMemoryBroker
from traider.messagebus.router import MessageRouter

import logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def _cpu_bound_worker_fn(message: EarningsEvent) -> None:
    logger.info(
        f"Also received earnings event for company: {message.company_name}"
    )
    time.sleep(1)
    return None


# ---------------------------------------------------------------------------
# Message-bus router and worker definitions
# ---------------------------------------------------------------------------


msg_broker: MessageBroker = InMemoryBroker()
msg_router = MessageRouter(msg_broker)

# ---------------------------------------------------------------------------
# Channel listeners
# ---------------------------------------------------------------------------


# A global process pool for CPU-bound work – will be initialised in main().
process_pool_global: ProcessPoolExecutor | None = None


@msg_router.route(listen_to=Channel.EARNINGS, ttl=20)
async def earnings_sink(
    router: MessageRouter,
    event: EarningsEvent,
) -> EarningsEvent | None:
    """Kick off a worker dynamically to retrieve the press-release that follows *event*."""

    logger.info(f"[earnings_sink] Triggering poller for {event.company_name}")
    # Start a background poller that will automatically be cancelled when the
    # router shuts down because it is spawned via `router.spawn_task`.
    router.spawn_task(
        earnings_press_release_poller(
            router,
            event.company_name,
            event.ticker,
        ),
        ttl=15,  # seconds – shortened for demo; use 24*3600 in real scenario
    )


#--------------------------------------------------------------------
# A worker that consumes press-release messages generated by the poller
#--------------------------------------------------------------------


@msg_router.route(listen_to=Channel.PRESS_RELEASE, ttl=20)
async def press_release_worker(
    router: MessageRouter,
    message: PressRelease,
) -> None:
    """Process a press-release once it has been published."""

    logger.info(
        f"[press_release_worker] Received press release for {message.ticker} — {message.title}"
    )


@msg_router.route(listen_to=Channel.EARNINGS, ttl=30)
async def cpu_heavy_worker(
    router: MessageRouter,
    event: EarningsEvent,
) -> EarningsEvent | None:
    """Handle CPU-bound work in a separate process pool."""

    assert process_pool_global is not None  # Should be initialised in *main*.
    loop = asyncio.get_running_loop()
    await loop.run_in_executor(process_pool_global, _cpu_bound_worker_fn, event)
    return event


@msg_router.route(publish_to=Channel.EARNINGS, ttl=5)
async def earnings_producer(router: MessageRouter):
    """Generate dummy earnings events."""

    await router.wait_until_ready()  # Ensure all listeners are ready
    try:
        for ticker in ["AAPL", "MSFT", "GOOG", "AMZN"]:

            earnings_event = EarningsEvent(
                id=uuid.uuid4().int,
                ticker=ticker,
                company_name=ticker,
                event_name=f"{ticker} Earnings",
                time_type="after_hours",
                earnings_call_time=datetime.now(),
                eps_estimate=random.random() * 10,
                eps_actual=random.random() * 10,
                eps_surprise=random.random() * 10,
                eps_surprise_percent=random.random() * 10,
                market_cap=random.random() * 1000000000,
            )

            await router.broker.publish(Channel.EARNINGS, earnings_event)
    except asyncio.CancelledError:
        logger.debug(f"[earnings_producer] Cancelled")

async def earnings_press_release_poller(
    router: MessageRouter,
    company_name: str,
    ticker: str
):
    """Simulate polling for a press-release that follows an earnings event.

    Runs in the background; it will be cancelled when the ttl expires or the router shuts down.
    """

    # Ensure the router finished initial startup (all initial nodes ready)
    await router.wait_until_ready()
    try:
        while True:
            await asyncio.sleep(2.5)

            # Craft a dummy press-release payload and publish it to the message-bus.
            press_release_msg = PressRelease(
                ticker=ticker,
                title=f"{company_name} beats EPS expectations",
                url="https://example.com/press-release",
                type="earnings",
                pub_date=datetime.now().isoformat(),
                company_name=company_name,
            )

            await router.broker.publish(Channel.PRESS_RELEASE, press_release_msg)
    except asyncio.CancelledError:
        logger.debug(f"[earnings_press_release_poller] Cancelled for {company_name} – ttl expired")


async def main() -> None:

    global process_pool_global

    cpu_cores = os.cpu_count() or 1
    process_pool_global = ProcessPoolExecutor(max_workers=cpu_cores)


    async with asyncio.TaskGroup() as tg:
        tg.create_task(msg_router.run())

    # Clean-up once all tasks are done.
    # process_pool_global.shutdown(wait=True)
    logger.info("Main task complete")


if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        logger.debug("Shutting down...")